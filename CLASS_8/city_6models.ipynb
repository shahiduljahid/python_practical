{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-14T12:17:52.831031Z","iopub.status.busy":"2021-11-14T12:17:52.830344Z","iopub.status.idle":"2021-11-14T12:18:06.459476Z","shell.execute_reply":"2021-11-14T12:18:06.458631Z","shell.execute_reply.started":"2021-11-14T12:17:52.830934Z"},"trusted":true},"outputs":[],"source":["#Installing the library containing some segmentation models\n","!pip install segmentation-models-pytorch"]},{"cell_type":"markdown","metadata":{},"source":["## 加载常用库"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T12:18:06.463391Z","iopub.status.busy":"2021-11-14T12:18:06.463160Z","iopub.status.idle":"2021-11-14T12:18:23.280375Z","shell.execute_reply":"2021-11-14T12:18:23.279577Z","shell.execute_reply.started":"2021-11-14T12:18:06.463359Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","!pip install torchviz\n","%matplotlib inline\n","import cv2\n","import random\n","import tqdm\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from PIL import Image\n","import torch.nn as nn\n","from torchviz import make_dot\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","#Importing the library into the notebook\n","import segmentation_models_pytorch as seg_models\n","from dotenv import load_dotenv\n","\n","load_dotenv()\n","output_folder_path = './output/city6_models'\n","os.makedirs(output_folder_path ,exist_ok=True)"]},{"cell_type":"markdown","metadata":{},"source":["## 可视化样本"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T12:18:23.282012Z","iopub.status.busy":"2021-11-14T12:18:23.281753Z","iopub.status.idle":"2021-11-14T12:18:23.640621Z","shell.execute_reply":"2021-11-14T12:18:23.639922Z","shell.execute_reply.started":"2021-11-14T12:18:23.281980Z"},"trusted":true},"outputs":[],"source":["DATASET = os.getenv('CITY_SCAPES_DATASET')\n","folder_path= DATASET\n","TrainFolder = os.path.join(folder_path+'train')\n","TestFolder = os.path.join(folder_path+'val')\n","train_images = TrainFolder\n","val_images = TestFolder\n","\n","train_files = os.listdir(train_images)\n","val_files = os.listdir(val_images)\n","\n","# Print any image of your choice from the training set\n","s_no = 20\n","\n","img = Image.open(os.path.join(train_images, train_files[s_no])).convert(\"RGB\")\n","\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 数据集加载"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T12:18:23.643028Z","iopub.status.busy":"2021-11-14T12:18:23.642360Z","iopub.status.idle":"2021-11-14T12:18:23.656476Z","shell.execute_reply":"2021-11-14T12:18:23.655695Z","shell.execute_reply.started":"2021-11-14T12:18:23.642998Z"},"trusted":true},"outputs":[],"source":["class data_load(object):\n","    def __init__(self, images_dir, batch_size, shuffle = True, rescale = 1.00, target_size = (128, 128)):\n","        super(data_load, self).__init__()\n","        self.images_dir = images_dir\n","        self.batch_size = batch_size\n","        self.rescale = rescale\n","        self.shuffle = shuffle\n","        self.target_size = target_size\n","        self.filenames = [os.path.join(self.images_dir, filename) for filename in os.listdir(self.images_dir)]\n","        self.step_number = 0\n","        self.total_steps = int(len(self.filenames) // self.batch_size)\n","        \n","    def generate_batch(self):\n","        start = self.step_number * self.batch_size\n","        stop = (self.step_number + 1) * self.batch_size\n","        filenames_batch = self.filenames[start:stop]\n","        \n","        images_batch = [cv2.imread(filename) for filename in filenames_batch]\n","        images_batch = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2RGB) for image in images_batch])\n","        \n","        # To separate images and their labels\n","        images_batch = np.array([(image[:, :256,], image[:, 256:]) for image in images_batch])\n","        \n","        images_batch = np.array([(cv2.resize(image, self.target_size), cv2.resize(mask, self.target_size)) for (image, mask) in images_batch], dtype = np.float32)\n","        images_batch = np.array([(np.moveaxis(image, -1, 0), np.moveaxis(mask, -1, 0)) for (image, mask) in images_batch])\n","        images_batch /= self.rescale\n","        images_batch = np.moveaxis(images_batch, 1, 0)\n","        \n","        return torch.Tensor(images_batch)\n","    \n","    def __next__(self):\n","        if self.step_number > self.total_steps:\n","            self.step_number = 0\n","        images, masks = self.generate_batch()\n","        self.step_number += 1\n","        return images, masks\n","    \n","    def __len__(self):\n","        return self.total_steps"]},{"cell_type":"markdown","metadata":{},"source":["## 模型库\n","\n","将要使用的模型的名称及其实例存储在字典中。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T12:18:23.658134Z","iopub.status.busy":"2021-11-14T12:18:23.657786Z","iopub.status.idle":"2021-11-14T12:18:28.126564Z","shell.execute_reply":"2021-11-14T12:18:28.125806Z","shell.execute_reply.started":"2021-11-14T12:18:23.658081Z"},"trusted":true},"outputs":[],"source":["names = [\"PSPNet\", \"UNet\", \"Unet++\", \"FPN\", \"DeepLab_V3\", \"DeepLab_V3+\"]\n","models_dict = {\n","    \"PSPNet\": seg_models.PSPNet(classes=3),\n","    \"UNet\": seg_models.Unet(classes=3),\n","    \"Unet++\": seg_models.UnetPlusPlus(classes=3),\n","    \"FPN\": seg_models.FPN(classes=3),\n","    \"DeepLab V3\": seg_models.DeepLabV3(classes=3),\n","    \"DeepLab V3+\": seg_models.DeepLabV3Plus(classes=3),\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T12:18:28.128196Z","iopub.status.busy":"2021-11-14T12:18:28.127894Z","iopub.status.idle":"2021-11-14T12:18:28.134442Z","shell.execute_reply":"2021-11-14T12:18:28.132962Z","shell.execute_reply.started":"2021-11-14T12:18:28.128156Z"},"trusted":true},"outputs":[],"source":["def dice(pred, label):\n","    pred = (pred > 0).float()\n","    return 2. * (pred*label).sum() / (pred+label).sum()"]},{"cell_type":"markdown","metadata":{},"source":["## 训练函数"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T12:18:29.660192Z","iopub.status.busy":"2021-11-14T12:18:29.659698Z","iopub.status.idle":"2021-11-14T12:18:29.678595Z","shell.execute_reply":"2021-11-14T12:18:29.677882Z","shell.execute_reply.started":"2021-11-14T12:18:29.660154Z"},"trusted":true},"outputs":[],"source":["def training( model, epochs ,batch_size ,optimizer ,criterion,logs,history):\n"," \n","    train_generator = data_load(images_dir = TrainFolder, batch_size = batch_size, rescale = 255.0)\n","    test_generator = data_load(images_dir = TestFolder, batch_size = batch_size, rescale = 255.0)\n","    \n","    device = torch.device('cpu')\n","    model.to(device)\n","    \n","    main_pbar = tqdm(range(epochs))\n","    main_pbar.set_description('common progress ')\n","    \n","    for epoch in main_pbar:\n","        running_params = dict(train_loss = [], \n","                               train_dice = [], \n","                               test_loss = [], \n","                               test_dice = [])\n","        train_pbar = tqdm(range(len(train_generator)))\n","        \n","        # # 计算训练的损失，并优化模型\n","        for step in train_pbar:\n","         \n","            train_imgs, train_masks = next(train_generator)\n","            train_imgs, train_masks = train_imgs.to(device), train_masks.to(device)\n","            \n","            optimizer.zero_grad()\n","            \n","            train_predictions = model(train_imgs)\n","\n","            train_loss = criterion(train_predictions, train_masks)\n","            train_loss.backward()\n","                \n","            train_dice = dice(pred = train_predictions, label = train_masks)\n","            optimizer.step()\n","            \n","            # 计算测试的损失，并优化模型\n","            with torch.no_grad():\n","                test_images, test_masks = next(test_generator)\n","                test_images, test_masks = test_images.to(device), test_masks.to(device)\n","            \n","                test_predictions = model(test_images)\n","    \n","                test_loss = criterion(test_predictions, test_masks)\n","        \n","                test_dice = dice(pred = test_predictions, label = test_masks)\n","                \n","            \n","            current_metrics = dict(train_loss = [train_loss.item(), ], \n","                                   train_dice = [train_dice.item(), ], \n","                                   test_loss = [test_loss.item(),], \n","                                   test_dice = [test_dice.item(),])\n","            \n","            running_params.update(current_metrics)\n","            \n","            mean_metrics = dict(zip(running_params.keys(), [(sum(tensor) / (step + 1)) for tensor in running_params.values()]))\n","    \n","            train_pbar.set_postfix(mean_metrics)\n","        \n","        temp = [train_loss.item(), train_dice.item(), test_loss.item(), test_dice.item()]\n","        logs.append(temp)\n","        history.update(running_params)\n","        best_loss = max(history['test_loss'])\n","        best_loss_index =  history['test_loss'].index(best_loss)\n","        current_loss_index = history['test_loss'].index(test_loss.item())\n","        if abs(current_loss_index - best_loss_index) >= 5:\n","            for param_group in optim.param_groups:\n","                if param_group['lr'] * 0.1 > 1e-6:\n","                    print('reduce learning rate to', {param_group['lr'] * 0.1})\n","                    param_group['lr'] *= 0.1\n"]},{"cell_type":"markdown","metadata":{},"source":["## 训练并保存权重"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-14T12:18:57.477997Z","iopub.status.busy":"2021-11-14T12:18:57.477682Z","iopub.status.idle":"2021-11-14T13:30:48.151857Z","shell.execute_reply":"2021-11-14T13:30:48.151114Z","shell.execute_reply.started":"2021-11-14T12:18:57.477946Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["histories = []   \n","MODELS_FOLDER = os.getenv('MODEL_FOLDER_PATH')\n","six_model_of_city = os.path.join(MODELS_FOLDER+'city6_models')\n","os.makedirs(six_model_of_city ,exist_ok=True)\n","model_folder_path=six_model_of_city\n","\n","for model_name, model_instance in models_dict.items():\n","    name = model_name\n","    model_name = model_instance\n","    model_name.to(\"cpu\")\n","    x = torch.zeros(8, 3, 128, 128, dtype=torch.float, requires_grad=False)\n","    x = x.to(\"cpu\")\n","    outputs_x = model_name(x)\n","    make_dot(outputs_x, params=dict(list(model_name.named_parameters())))\n","    \n","    # 实例化优化器\n","    optimizer = torch.optim.Adam(params = model_name.parameters(), \n","                             lr=1e-4, \n","                             betas=(0.9, 0.999), \n","                             eps=1e-08, \n","                             weight_decay=0, \n","                             amsgrad=False)\n","\n","    criterion = torch.nn.BCEWithLogitsLoss()\n","    \n","    history = dict(train_loss = [], \n","                   train_dice = [], \n","                   test_loss = [], \n","                   test_dice = [])\n","    \n","    logs = []\n","    \n","    # 训练模型\n","    training(model = model_name, epochs = 20, batch_size = 32 , optimizer= optimizer,criterion=criterion ,logs=logs,history=history)\n","    \n","    histories.append(logs)\n","    \n","    # 将每个模型的模型权重保存在工作目录中\n","   \n","    weights_path = os.path.join(model_folder_path, name + '_weights.pth')\n","    logs_path = os.path.join(model_folder_path, name + '_logs')\n","    torch.save(model_name.state_dict(), weights_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 评估每个模型"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:31:32.943829Z","iopub.status.busy":"2021-11-14T13:31:32.943566Z","iopub.status.idle":"2021-11-14T13:31:32.952365Z","shell.execute_reply":"2021-11-14T13:31:32.951163Z","shell.execute_reply.started":"2021-11-14T13:31:32.943800Z"},"trusted":true},"outputs":[],"source":["def show(model_name, num_cols):\n","    generator = data_load(images_dir = val_images, \n","                           batch_size = 8, \n","                           rescale = 255.0)\n","    result = []\n","    for iteration in range(num_cols):\n","        images, masks = next(generator)\n","        images_1 = images.to(\"cpu\")\n","        \n","        prediction = torch.sigmoid(model_name(images_1))\n","        prediction = prediction.cpu().detach().numpy()\n","        prediction = np.moveaxis(prediction, 1, -1)\n","        masks = np.moveaxis(masks.numpy(), 1, -1)\n","        images = np.moveaxis(images.numpy(), 1, -1)\n","        prediction = np.concatenate(prediction)\n","        images = np.concatenate(images)\n","        masks = np.concatenate(masks)\n","        outputs = np.hstack([images, masks, prediction])\n","        result.append(outputs)\n","    result = np.hstack(result)\n","    plt.figure(figsize = (30, 30))\n","    plt.axis('off')\n","    plt.imshow(result)"]},{"cell_type":"markdown","metadata":{},"source":["# PSPNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:31:50.062414Z","iopub.status.busy":"2021-11-14T13:31:50.062010Z","iopub.status.idle":"2021-11-14T13:31:52.045342Z","shell.execute_reply":"2021-11-14T13:31:52.043846Z","shell.execute_reply.started":"2021-11-14T13:31:50.062379Z"},"trusted":true},"outputs":[],"source":["name = \"PSPNet\"\n","model_name = models_dict[\"PSPNet\"]\n","model_name.load_state_dict(torch.load(os.path.join(model_folder_path, name + '_weights.pth')))\n","model_name.eval()\n","show(model_name, num_cols = 2)"]},{"cell_type":"markdown","metadata":{},"source":["# UNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:32:04.107927Z","iopub.status.busy":"2021-11-14T13:32:04.107652Z","iopub.status.idle":"2021-11-14T13:32:06.215300Z","shell.execute_reply":"2021-11-14T13:32:06.214575Z","shell.execute_reply.started":"2021-11-14T13:32:04.107898Z"},"trusted":true},"outputs":[],"source":["name = \"UNet\"\n","model_name = models_dict[\"UNet\"]\n","model_name.load_state_dict(torch.load(os.path.join(model_folder_path, name + '_weights.pth')))\n","model_name.eval()\n","show(model_name, num_cols = 2)"]},{"cell_type":"markdown","metadata":{},"source":["# UNet++"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:32:29.798941Z","iopub.status.busy":"2021-11-14T13:32:29.798667Z","iopub.status.idle":"2021-11-14T13:32:31.884819Z","shell.execute_reply":"2021-11-14T13:32:31.884097Z","shell.execute_reply.started":"2021-11-14T13:32:29.798909Z"},"trusted":true},"outputs":[],"source":["name = \"Unet++\"\n","model_name = models_dict[\"Unet++\"]\n","model_name.load_state_dict(torch.load(os.path.join(model_folder_path, name + '_weights.pth')))\n","model_name.eval()\n","show(model_name, num_cols = 2)"]},{"cell_type":"markdown","metadata":{},"source":["# FPN"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:35:50.152217Z","iopub.status.busy":"2021-11-14T13:35:50.151930Z","iopub.status.idle":"2021-11-14T13:35:52.176008Z","shell.execute_reply":"2021-11-14T13:35:52.175209Z","shell.execute_reply.started":"2021-11-14T13:35:50.152182Z"},"trusted":true},"outputs":[],"source":["name = \"FPN\"\n","model_name = models_dict[\"FPN\"]\n","model_name.load_state_dict(torch.load(os.path.join(model_folder_path, name + '_weights.pth')))\n","model_name.eval()\n","show(model_name, num_cols = 2)"]},{"cell_type":"markdown","metadata":{},"source":["# DeepLab V3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:36:03.662724Z","iopub.status.busy":"2021-11-14T13:36:03.661960Z","iopub.status.idle":"2021-11-14T13:36:05.802042Z","shell.execute_reply":"2021-11-14T13:36:05.801235Z","shell.execute_reply.started":"2021-11-14T13:36:03.662671Z"},"trusted":true},"outputs":[],"source":["name = \"DeepLab V3\"\n","model_name = models_dict[\"DeepLab V3\"]\n","model_name.load_state_dict(torch.load(os.path.join(model_folder_path, name + '_weights.pth')))\n","model_name.eval()\n","show(model_name, num_cols = 2)"]},{"cell_type":"markdown","metadata":{},"source":["# DeepLab V3+"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:36:14.469726Z","iopub.status.busy":"2021-11-14T13:36:14.469286Z","iopub.status.idle":"2021-11-14T13:36:16.510019Z","shell.execute_reply":"2021-11-14T13:36:16.509287Z","shell.execute_reply.started":"2021-11-14T13:36:14.469688Z"},"trusted":true},"outputs":[],"source":["name = \"DeepLab V3+\"\n","model_name = models_dict[\"DeepLab V3+\"]\n","model_name.load_state_dict(torch.load(os.path.join(model_folder_path, name + '_weights.pth')))\n","model_name.eval()\n","show(model_name, num_cols = 2)"]},{"cell_type":"markdown","metadata":{},"source":["## 画loss曲线\n","\n","将所有训练值和测试值存储在DataFrames字典中，以便轻松获取"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:36:28.065777Z","iopub.status.busy":"2021-11-14T13:36:28.065515Z","iopub.status.idle":"2021-11-14T13:36:28.259660Z","shell.execute_reply":"2021-11-14T13:36:28.258914Z","shell.execute_reply.started":"2021-11-14T13:36:28.065748Z"},"trusted":true},"outputs":[],"source":["DataFrames = {}\n","for i in range(6):\n","    name_df = pd.DataFrame(columns=['Train Loss', 'Train Dice Coefficient', 'Test Loss', 'Test Dice Coefficient'])\n","    for j in range(len(histories[i])):\n","        name_df.loc[len(name_df.index)] = histories[i][j]\n","    DataFrames[names[i]] = name_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:39:04.530558Z","iopub.status.busy":"2021-11-14T13:39:04.529973Z","iopub.status.idle":"2021-11-14T13:39:04.559105Z","shell.execute_reply":"2021-11-14T13:39:04.558077Z","shell.execute_reply.started":"2021-11-14T13:39:04.530518Z"},"trusted":true},"outputs":[],"source":["DataFrames"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-14T13:59:27.295066Z","iopub.status.busy":"2021-11-14T13:59:27.294789Z","iopub.status.idle":"2021-11-14T13:59:32.372834Z","shell.execute_reply":"2021-11-14T13:59:32.372174Z","shell.execute_reply.started":"2021-11-14T13:59:27.295035Z"},"trusted":true},"outputs":[],"source":["for i in names:\n","    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize = (40, 20))\n","    fig.suptitle('Plots for '+i)\n","    ax1.plot(DataFrames[i][\"Train Loss\"])\n","#     ax1.set_ylim([0.5, 0.6])\n","    ax1.set_xlabel('Epochs')\n","    ax1.set_ylabel('Train Loss')\n","    \n","    ax3.plot(DataFrames[i][\"Test Loss\"])\n","#     ax3.set_ylim([0.5, 0.6])\n","    ax3.set_xlabel('Epochs')\n","    ax3.set_ylabel('Test Loss')\n","    \n","    ax2.plot(DataFrames[i][\"Train Dice Coefficient\"])\n","#     ax2.set_ylim([0.4, 0.5])\n","    ax2.set_xlabel('Epochs')\n","    ax2.set_ylabel('Train Dice Coefficient')\n","    \n","    ax4.plot(DataFrames[i][\"Test Dice Coefficient\"])\n","#     ax4.set_ylim([0.4, 0.5])\n","    ax4.set_xlabel('Epochs')\n","    ax4.set_ylabel('Test Dice Coefficient')"]},{"cell_type":"markdown","metadata":{},"source":["### 请比较一下各个模型的性能，给出性能最好的模型"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
